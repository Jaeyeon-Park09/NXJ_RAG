"""
PDF íŒŒì„œ ë©”ì¸ ëª¨ë“ˆ - ëª¨ë“ˆí™”ëœ êµ¬ì¡°
"""

import fitz  # PyMuPDF
import json
import re
import os
import time
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import asdict
import logging
from pathlib import Path

# ë¡œì»¬ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ import
from utils import (
    TextBlock, LogManager, PDFTypeDetector, 
    TableDetector, TextChunker, MarkdownConverter
)


class PDFParser:
    """ë¦¬íŒ©í† ë§ëœ PDF íŒŒì„œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, log_manager: LogManager):
        self.log_manager = log_manager
        self._reset_state()
    
    def _reset_state(self):
        """íŒŒì‹± ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.text_blocks: List[TextBlock] = []
        self.font_sizes: Dict[float, int] = {}
        self.heading_sizes: List[float] = []
        self.is_scanned_pdf: bool = False
        self.table_detector = TableDetector()
        self.text_chunker = TextChunker(window_size=3)
        self.chunks: List[Dict] = []
        self.current_file_name = ""
        self.page_mapping: Dict[str, int] = {}  # í…ìŠ¤íŠ¸ -> í˜ì´ì§€ ë²ˆí˜¸ ë§¤í•‘
    
    def parse_pdf(self, pdf_path: str) -> Dict[str, Any]:
        """PDF íŒŒì¼ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
        # ìƒíƒœ ì´ˆê¸°í™”
        self._reset_state()
        self.current_file_name = Path(pdf_path).name
        logging.info(f"íŒŒì‹± ì‹œì‘: {self.current_file_name}")
        
        start_time = time.time()
        
        try:
            # 1ë‹¨ê³„: PDF ì—´ê¸° ë° íƒ€ì… ê°ì§€
            self.log_manager.log_progress(1, 7, f"PDF ì—´ê¸°: {self.current_file_name}")
            doc = self._open_and_validate_pdf(pdf_path)
            
            # 2ë‹¨ê³„: íƒ€ì… ê°ì§€
            self.log_manager.log_progress(2, 7, "PDF íƒ€ì… ê°ì§€ ì¤‘...")
            pdf_type = PDFTypeDetector.detect_pdf_type(doc)
            logging.info(f"PDF íƒ€ì…: {pdf_type}")
            
            if pdf_type == "scanned":
                self.is_scanned_pdf = True
                logging.warning(f"ìŠ¤ìº”ë³¸ PDF ê°ì§€ë¨: {pdf_path} - íŒŒì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                doc.close()
                return self._create_empty_result(pdf_path)
            
            # 3ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¸”ë¡ ì¶”ì¶œ
            self.log_manager.log_progress(3, 7, "í…ìŠ¤íŠ¸ ë¸”ë¡ ì¶”ì¶œ ì¤‘...")
            self.text_blocks = self._extract_text_blocks(doc)
            
            # 4ë‹¨ê³„: ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
            self.log_manager.log_progress(4, 7, "ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì¤‘...")
            self._analyze_document_structure()
            
            # 5ë‹¨ê³„: Markdown ë³€í™˜
            self.log_manager.log_progress(5, 7, "Markdown ë³€í™˜ ì¤‘...")
            markdown_converter = MarkdownConverter(self.table_detector.detected_tables)
            markdown_content = markdown_converter.convert_blocks_to_markdown(self.text_blocks)
            
            # 6ë‹¨ê³„: í…ìŠ¤íŠ¸ ì²­í‚¹
            self.log_manager.log_progress(6, 7, "í…ìŠ¤íŠ¸ ì²­í‚¹ ì¤‘...")
            self.chunks = self._perform_chunking(markdown_content)
            
            # 7ë‹¨ê³„: ê²°ê³¼ ìƒì„±
            self.log_manager.log_progress(7, 7, "ê²°ê³¼ ìƒì„± ì™„ë£Œ")
            result = self._create_result(pdf_path, markdown_content)
            
            elapsed_time = time.time() - start_time
            logging.info(f"íŒŒì‹± ì™„ë£Œ: {self.current_file_name} ({elapsed_time:.2f}ì´ˆ)")
            
            doc.close()
            return result
            
        except Exception as e:
            logging.error(f"íŒŒì‹± ì˜¤ë¥˜: {self.current_file_name} - {str(e)}")
            raise
    
    def _open_and_validate_pdf(self, pdf_path: str) -> fitz.Document:
        """PDF íŒŒì¼ì„ ì—´ê³  ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
        try:
            doc = fitz.open(pdf_path)
            if doc.page_count == 0:
                raise ValueError("ë¹ˆ PDF íŒŒì¼")
            logging.debug(f"PDF ì—´ê¸° ì„±ê³µ: {doc.page_count}í˜ì´ì§€")
            return doc
        except Exception as e:
            raise ValueError(f"PDF íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨: {str(e)}")
    
    def _create_empty_result(self, pdf_path: str) -> Dict[str, Any]:
        """ìŠ¤ìº”ë³¸ PDFìš© ë¹ˆ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        return {
            "file_name": Path(pdf_path).name,
            "total_pages": 0,
            "pdf_type": "scanned",
            "font_analysis": {"font_sizes_frequency": {}, "heading_sizes": []},
            "table_analysis": {"total_tables": 0, "tables_info": []},
            "text_blocks": [],
            "markdown_content": "",
            "chunks": [],
            "chunking_analysis": {
                "total_chunks": 0,
                "avg_chunk_length": 0,
                "min_chunk_length": 0,
                "max_chunk_length": 0,
                "total_characters": 0,
                "total_words": 0,
                "window_size": 3
            },
            "statistics": {
                "total_text_blocks": 0,
                "heading_count": 0,
                "paragraph_count": 0,
                "list_item_count": 0,
                "table_cell_count": 0,
                "tables_detected": 0,
                "chunks_generated": 0
            }
        }
    
    def _extract_text_blocks(self, doc: fitz.Document) -> List[TextBlock]:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        text_blocks = []
        total_pages = len(doc)
        
        logging.debug(f"í…ìŠ¤íŠ¸ ë¸”ë¡ ì¶”ì¶œ ì‹œì‘: {total_pages}í˜ì´ì§€")
        
        for page_num in range(total_pages):
            page_progress = f"í˜ì´ì§€ {page_num + 1}/{total_pages} ì²˜ë¦¬ ì¤‘"
            logging.debug(page_progress)
            
            page = doc.load_page(page_num)
            blocks = page.get_text("dict")
            
            # í˜ì´ì§€ë³„ í‘œ ê°ì§€
            page_tables = self.table_detector.detect_tables_in_page(blocks["blocks"])
            self.table_detector.detected_tables.extend(page_tables)
            
            # í…ìŠ¤íŠ¸ ë¸”ë¡ ì¶”ì¶œ
            page_blocks = self._extract_page_blocks(blocks["blocks"], page_num, page_tables)
            text_blocks.extend(page_blocks)
        
        logging.info(f"ì¶”ì¶œ ì™„ë£Œ: {len(text_blocks)}ê°œ ë¸”ë¡, {len(self.table_detector.detected_tables)}ê°œ í‘œ")
        return text_blocks
    
    def _extract_page_blocks(self, blocks: List[Dict], page_num: int, page_tables: List[Dict]) -> List[TextBlock]:
        """í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        page_blocks = []
        
        for block in blocks:
            if "lines" not in block:  # ì´ë¯¸ì§€ ë¸”ë¡ ì œì™¸
                continue
            
            is_in_table = self.table_detector.is_block_in_table(block["bbox"])
            
            for line in block["lines"]:
                text_block = self._create_text_block_from_line(line, block["bbox"], page_num + 1, is_in_table)
                if text_block:
                    page_blocks.append(text_block)
                    self._update_font_statistics(text_block.font_size)
                    # í˜ì´ì§€ ë§¤í•‘ ì •ë³´ ì¶”ê°€ (ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ë¸”ë¡ë§Œ)
                    if not self.page_mapping or text_block.text not in self.page_mapping:
                        self.page_mapping[text_block.text] = page_num + 1
        
        return page_blocks
    
    def _create_text_block_from_line(self, line: Dict, bbox: List[float], page_num: int, is_in_table: bool) -> Optional[TextBlock]:
        """ë¼ì¸ì—ì„œ í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        line_text = ""
        font_size = 0
        font_name = ""
        
        for span in line["spans"]:
            line_text += span["text"]
            font_size = span["size"]
            font_name = span["font"]
        
        line_text = line_text.strip()
        if not line_text:
            return None
        
        return TextBlock(
            text=line_text,
            font_size=font_size,
            font_name=font_name,
            bbox=bbox,
            page_num=page_num,
            is_in_table=is_in_table
        )
    
    def _update_font_statistics(self, font_size: float):
        """í°íŠ¸ í¬ê¸° í†µê³„ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        self.font_sizes[font_size] = self.font_sizes.get(font_size, 0) + 1
    
    def _perform_chunking(self, markdown_content: str) -> List[Dict]:
        """Markdown í…ìŠ¤íŠ¸ë¥¼ ì²­í‚¹í•©ë‹ˆë‹¤."""
        if not markdown_content.strip():
            logging.debug("ì²­í‚¹ ê±´ë„ˆë›°ê¸°: ë¹ˆ í…ìŠ¤íŠ¸")
            return []
        
        chunks = self.text_chunker.chunk_text(
            markdown_content, 
            self.current_file_name, 
            self.page_mapping
        )
        logging.info(f"ì²­í‚¹ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„± (í˜ì´ì§€ ë§¤í•‘: {len(self.page_mapping)}ê°œ)")
        return chunks
    
    def _analyze_document_structure(self) -> None:
        """ë¬¸ì„œ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ ë¸”ë¡ íƒ€ì…ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
        if not self.font_sizes:
            logging.debug("í°íŠ¸ ì •ë³´ ì—†ìŒ - êµ¬ì¡° ë¶„ì„ ìƒëµ")
            return
        
        # ì œëª© í°íŠ¸ í¬ê¸° ê²°ì •
        self._determine_heading_sizes()
        
        # ë¸”ë¡ íƒ€ì… ì„¤ì •
        self._assign_block_types()
        
        logging.debug(f"êµ¬ì¡° ë¶„ì„ ì™„ë£Œ: ì œëª© í¬ê¸° {len(self.heading_sizes)}ê°œ")
    
    def _determine_heading_sizes(self) -> None:
        """ì œëª©ìœ¼ë¡œ ì‚¬ìš©ë  í°íŠ¸ í¬ê¸°ë“¤ì„ ê²°ì •í•©ë‹ˆë‹¤."""
        body_font_size = max(self.font_sizes, key=self.font_sizes.get)
        
        potential_headings = [
            size for size in self.font_sizes.keys() 
            if size > body_font_size and self.font_sizes[size] > 1
        ]
        
        self.heading_sizes = sorted(potential_headings, reverse=True)
        logging.debug(f"ë³¸ë¬¸ í°íŠ¸: {body_font_size}, ì œëª© í°íŠ¸: {self.heading_sizes}")
    
    def _assign_block_types(self) -> None:
        """í…ìŠ¤íŠ¸ ë¸”ë¡ë“¤ì˜ íƒ€ì…ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
        for block in self.text_blocks:
            if block.is_in_table:
                block.block_type = "table_cell"
            elif block.font_size in self.heading_sizes:
                block.block_type = "heading"
                block.level = self.heading_sizes.index(block.font_size) + 1
            elif self._is_list_item(block.text):
                block.block_type = "list_item"
            else:
                block.block_type = "paragraph"
    
    def _is_list_item(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ê°€ ë¦¬ìŠ¤íŠ¸ í•­ëª©ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
        # í•œêµ­ì–´ ë¦¬ìŠ¤íŠ¸ íŒ¨í„´ë“¤
        patterns = [
            r'^[0-9]+\.',           # 1. 2. 3.
            r'^[ê°€-í£]\.',          # ê°€. ë‚˜. ë‹¤.
            r'^\([0-9]+\)',         # (1) (2) (3)
            r'^\([ê°€-í£]\)',        # (ê°€) (ë‚˜) (ë‹¤)
            r'^[â‘ -â‘³]',             # â‘  â‘¡ â‘¢
            r'^[ã‰ -ã‰¯]',             # ã‰  ã‰¡ ã‰¢
            r'^[-â€¢â–ªâ–«â—¦]',           # ë¶ˆë¦¿ í¬ì¸íŠ¸
            r'^â—‹',                  # â—‹
            r'^â—',                  # â—
            r'^â—†',                  # â—†
            r'^â—‡',                  # â—‡
        ]
        
        for pattern in patterns:
            if re.match(pattern, text.strip()):
                return True
        return False
    
    def _create_result(self, pdf_path: str, markdown_content: str) -> Dict[str, Any]:
        """íŒŒì‹± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        return {
            "file_name": Path(pdf_path).name,
            "total_pages": self.text_blocks[-1].page_num if self.text_blocks else 0,
            "pdf_type": "scanned" if self.is_scanned_pdf else "normal",
            "font_analysis": {
                "font_sizes_frequency": self.font_sizes,
                "heading_sizes": self.heading_sizes
            },
            "table_analysis": {
                "total_tables": len(self.table_detector.detected_tables),
                "tables_info": [
                    {
                        "bbox": table["bbox"],
                        "num_rows": table["num_rows"],
                        "num_cols": table["num_cols"]
                    } for table in self.table_detector.detected_tables
                ]
            },
            "text_blocks": [asdict(block) for block in self.text_blocks],
            "markdown_content": markdown_content,
            "chunks": self.chunks,
            "chunking_analysis": self.text_chunker.get_chunking_stats(self.chunks),
            "statistics": self._calculate_statistics()
        }
    
    def _calculate_statistics(self) -> Dict[str, int]:
        """ë¬¸ì„œ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        return {
            "total_text_blocks": len(self.text_blocks),
            "heading_count": len([b for b in self.text_blocks if b.block_type == "heading"]),
            "paragraph_count": len([b for b in self.text_blocks if b.block_type == "paragraph"]),
            "list_item_count": len([b for b in self.text_blocks if b.block_type == "list_item"]),
            "table_cell_count": len([b for b in self.text_blocks if b.block_type == "table_cell"]),
            "tables_detected": len(self.table_detector.detected_tables),
            "chunks_generated": len(self.chunks)
        }
    
    def save_results(self, pdf_path: str, output_dir: str = "output") -> Tuple[str, str]:
        """PDF íŒŒì‹± ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        os.makedirs(output_dir, exist_ok=True)
        
        result = self.parse_pdf(pdf_path)
        
        # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
        base_name = Path(pdf_path).stem
        safe_name = re.sub(r'[^\wê°€-í£\-_]', '_', base_name)
        
        # íŒŒì¼ ì €ì¥
        json_path = Path(output_dir) / f"{safe_name}.json"
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        return str(json_path)


def main():
    """ë¦¬íŒ©í† ë§ëœ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    pdf_directory = Path("pdf_files")
    output_directory = Path("output")
    
    # ë¡œê·¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    log_manager = LogManager()
    
    # PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    pdf_files = list(pdf_directory.glob("*.pdf"))
    
    if not pdf_files:
        logging.error(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_directory}")
        return
    
    logging.info(f"ì´ {len(pdf_files)}ê°œ PDF íŒŒì¼ ë°œê²¬")
    print(f"\nğŸš€ PDF íŒŒì‹± ì‹œì‘ - {len(pdf_files)}ê°œ íŒŒì¼")
    print("=" * 50)
    
    start_time = time.time()
    success_count = 0
    error_count = 0
    
    # ê° PDF íŒŒì¼ ì²˜ë¦¬
    for i, pdf_file in enumerate(pdf_files, 1):
        print(f"\nğŸ“„ [{i}/{len(pdf_files)}] {pdf_file.name}")
        print("-" * 40)
        
        try:
            # íŒŒì¼ë³„ íŒŒì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            parser = PDFParser(log_manager)
            json_path = parser.save_results(str(pdf_file), str(output_directory))
            
            if parser.is_scanned_pdf:
                print("  âš ï¸  ìŠ¤ìº”ë³¸ PDF - íŒŒì‹± ì œì™¸")
                logging.warning(f"ìŠ¤ìº”ë³¸ PDF ì œì™¸: {pdf_file.name}")
            else:
                print(f"  âœ… JSON: {Path(json_path).name}")
                
                # í†µê³„ ì •ë³´ ì¶œë ¥
                stats = parser._calculate_statistics()
                print(f"  ğŸ“Š ë¸”ë¡: {stats['total_text_blocks']}ê°œ")
                print(f"  ğŸ“Š í‘œ: {stats['tables_detected']}ê°œ")
                print(f"  ğŸ§© ì²­í¬: {stats['chunks_generated']}ê°œ")
                
                success_count += 1
                
        except Exception as e:
            error_count += 1
            print(f"  âŒ ì˜¤ë¥˜: {str(e)}")
            logging.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {pdf_file.name} - {str(e)}")
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    total_time = time.time() - start_time
    print("\n" + "=" * 50)
    print("ğŸ¯ ìµœì¢… ê²°ê³¼")
    print(f"  âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"  âŒ ì‹¤íŒ¨: {error_count}ê°œ")
    print(f"  â±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"  ğŸ“ ë¡œê·¸ íŒŒì¼: {log_manager.log_file}")
    
    logging.info(f"=== íŒŒì‹± ì™„ë£Œ - ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}, ì‹œê°„: {total_time:.2f}ì´ˆ ===")


if __name__ == "__main__":
    main() 